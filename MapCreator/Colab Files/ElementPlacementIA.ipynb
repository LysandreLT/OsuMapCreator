{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "machine_shape": "hm",
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "#Connect Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "id": "yANdRnBgESpX",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "99db81b2-a6bb-46b1-f931-65ce8249d410"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vPnyJLWRlJoP"
   },
   "outputs": [],
   "source": [
    "import librosa.feature\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def load_melspectrogram(audio_path, plot=False):\n",
    "    y, sr = librosa.load(audio_path, sr=22050, mono=True)\n",
    "    melspectrogram = np.zeros((128, 20000), dtype=float)\n",
    "    melspectrogram_full = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "    melspectrogram[:, :melspectrogram_full.shape[1]] = melspectrogram_full[:, :20000]\n",
    "    # times[i] = frames[i] * hop_length / sr -> 7,739984882842026 min\n",
    "    if plot:\n",
    "        fig, ax = plt.subplots()\n",
    "        S_dB = librosa.power_to_db(melspectrogram, ref=np.max)\n",
    "        img = librosa.display.specshow(S_dB, x_axis='time',\n",
    "                                       y_axis='mel', sr=sr, ax=ax)\n",
    "        fig.colorbar(img, ax=ax, format='%+2.0f dB')\n",
    "        ax.set(title='Mel-frequency spectrogram')\n",
    "        plt.show()\n",
    "    return melspectrogram.transpose()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    path = \"C:/Users/Lysandre/Documents/GitHub/OsuMapCreator/MapCreator/datasets/maps/33688 DJ Okawari - Flower \" \\\n",
    "           \"Dance/Flower Dance.mp3\"\n",
    "    mel_spectro = load_melspectrogram(path, plot=True)\n",
    "    print(mel_spectro.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from MapCreator.Utils.trainingMapParser import load_beatmap_attributes\n",
    "from pydub import AudioSegment\n",
    "\n",
    "\n",
    "def flatten(l):\n",
    "    flat_list = []\n",
    "    for sublist in l:\n",
    "        if type(sublist) == list:\n",
    "            for item in sublist:\n",
    "                flat_list.append(item)\n",
    "        else:\n",
    "            flat_list.append(sublist)\n",
    "    return flat_list\n",
    "\n",
    "\n",
    "def prepare_dataset(data, segment_length=5529, max_hitObject=120):\n",
    "    end_of_sequence = 10002\n",
    "    start_of_sequence = 10001\n",
    "    music_segments = []  # List to store the split segments\n",
    "    diff_segments = []  # List to store the split segments\n",
    "    for beatmap in data:\n",
    "        print(beatmap[\"audio\"])\n",
    "        # spectrogram using stft\n",
    "        if beatmap[\"audio\"].endswith(\".mp3\"):\n",
    "            # convert mp3 to wav\n",
    "            sound = AudioSegment.from_mp3(beatmap[\"audio\"])\n",
    "            beatmap[\"audio\"] = beatmap[\"audio\"][:-4] + \".wav\"\n",
    "            sound.export(beatmap[\"audio\"], format=\"wav\")\n",
    "        audio = tf.io.read_file(beatmap[\"audio\"])\n",
    "        audio, _ = tf.audio.decode_wav(audio, 1)\n",
    "        audio = tf.squeeze(audio, axis=-1)\n",
    "        stfts = tf.signal.stft(audio, frame_length=200, frame_step=80, fft_length=256)\n",
    "        x = tf.math.pow(tf.abs(stfts), 0.5)\n",
    "        # normalisation\n",
    "        means = tf.math.reduce_mean(x, 1, keepdims=True)\n",
    "        stddevs = tf.math.reduce_std(x, 1, keepdims=True)\n",
    "        x = (x - means) / stddevs\n",
    "        audio_len = tf.shape(x)[0]\n",
    "        # slicing to 10 seconds\n",
    "        num_segments = int(np.ceil(audio_len / segment_length))\n",
    "\n",
    "        for i in range(num_segments):\n",
    "            start_sample = i * segment_length\n",
    "            end_sample = start_sample + segment_length\n",
    "\n",
    "            # Split the spectrogram and add the segment to the list\n",
    "            segment = x[start_sample:end_sample, :]\n",
    "\n",
    "            # Pad the last segment if necessary\n",
    "            if tf.shape(segment)[0] < segment_length:\n",
    "                paddings = tf.constant([[0, segment_length], [0, 0]])\n",
    "                segment = tf.pad(segment, paddings, \"CONSTANT\")[:segment_length, :]\n",
    "\n",
    "            music_segments.append(segment)\n",
    "\n",
    "        # Slicing of the diff\n",
    "        hitpoints = beatmap[\"text\"]\n",
    "        segment = [start_of_sequence]\n",
    "        segment_id = 1\n",
    "        for hitpoint in hitpoints:\n",
    "            if hitpoint[4] >= 10000:\n",
    "                print(\"Spinner ignorÃ© :\" + str(hitpoint[4]))\n",
    "                continue\n",
    "            # TODO : change 10000 in function of segment_length\n",
    "            if 10000 * segment_id > hitpoint[2]:\n",
    "                hitpoint[2] -= 10000 * (segment_id - 1)\n",
    "                segment.append(hitpoint.tolist())\n",
    "            else:\n",
    "                for i in range(int(hitpoint[2] / 10000)-(segment_id-1)):\n",
    "                    segment.append(end_of_sequence)\n",
    "                    segment = flatten(segment)\n",
    "\n",
    "                    # Padding the segment\n",
    "                    segment += [0] * (max_hitObject*13 - len(segment))\n",
    "                    if len(segment) > max_hitObject*13:\n",
    "                        print(\"Warning : the length of the sequence exceeds the fixed limit\")\n",
    "                    diff_segments.append(segment)\n",
    "                    segment = [start_of_sequence]\n",
    "                    segment_id += 1\n",
    "                hitpoint[2] -= 10000 * (segment_id - 1)\n",
    "                segment.append(hitpoint.tolist())\n",
    "        \"\"\"if len(diff_segments[-1]) != max_hitObject*13:\n",
    "            print(\"Ajustement\")\n",
    "            diff_segments[-1].append(end_of_sequence)\n",
    "            diff_segments[-1] += [0] * (max_hitObject*13 - len(diff_segments[-1]) - 1)\n",
    "            print(len(diff_segments[-1]))\"\"\"\n",
    "\n",
    "        for i in range(num_segments - segment_id+1):\n",
    "            diff_segments.append([start_of_sequence, end_of_sequence] + [0] * (max_hitObject*13 - 2))\n",
    "\n",
    "    return music_segments, diff_segments\n",
    "\n",
    "\n",
    "def create_text_and_audio_ds(data, bs=4):\n",
    "    music_segments, diff_segments = prepare_dataset(data)\n",
    "    print(\"Number of diff segments : \" + str(len(diff_segments)))\n",
    "    print(\"Number of music segments : \" + str(len(music_segments)))\n",
    "    audio_ds = tf.data.Dataset.from_tensor_slices(music_segments)\n",
    "    map_ds = tf.data.Dataset.from_tensor_slices(diff_segments)\n",
    "    ds = tf.data.Dataset.zip((audio_ds, map_ds))\n",
    "    ds = ds.map(lambda x, y: {\"source\": x, \"target\": y})\n",
    "    ds = ds.batch(bs)\n",
    "    ds = ds.prefetch(tf.data.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "\n",
    "def load_beatmaps_and_musics(paths, max_nb_musics=1000):\n",
    "    data = []\n",
    "    diff = []\n",
    "    for i, path in enumerate(paths):\n",
    "        if max_nb_musics and i >= max_nb_musics:\n",
    "            break\n",
    "        for beatmap in path[0]:\n",
    "            df_temp, difficulty = load_beatmap_attributes(beatmap, max_hit_object=None)\n",
    "            df_temp = df_temp.transpose()\n",
    "            diff.append(difficulty)\n",
    "            data.append({\"audio\": path[1], \"text\": df_temp})\n",
    "    return data\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "\n",
    "\n",
    "class TokenEmbedding(layers.Layer):\n",
    "    def __init__(self, num_vocab=10002, maxlen=100, num_hid=64):\n",
    "        super().__init__()\n",
    "        self.emb = tf.keras.layers.Embedding(num_vocab, num_hid)\n",
    "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=num_hid)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-1]\n",
    "        x = self.emb(x)\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        return x + positions\n",
    "\n",
    "\n",
    "class SpeechFeatureEmbedding(layers.Layer):\n",
    "    def __init__(self, num_hid=64, maxlen=100):\n",
    "        super().__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv1D(\n",
    "            num_hid, 11, strides=2, padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv2 = tf.keras.layers.Conv1D(\n",
    "            num_hid, 11, strides=2, padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.conv3 = tf.keras.layers.Conv1D(\n",
    "            num_hid, 11, strides=2, padding=\"same\", activation=\"relu\"\n",
    "        )\n",
    "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=num_hid)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        return self.conv3(x)\n",
    "\n",
    "\n",
    "class TransformerEncoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, feed_forward_dim, rate=0.1):\n",
    "        super().__init__()\n",
    "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [\n",
    "                layers.Dense(feed_forward_dim, activation=\"relu\"),\n",
    "                layers.Dense(embed_dim),\n",
    "            ]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "\n",
    "class TransformerDecoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, feed_forward_dim, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.self_att = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim\n",
    "        )\n",
    "        self.enc_att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.self_dropout = layers.Dropout(0.5)\n",
    "        self.enc_dropout = layers.Dropout(0.1)\n",
    "        self.ffn_dropout = layers.Dropout(0.1)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [\n",
    "                layers.Dense(feed_forward_dim, activation=\"relu\"),\n",
    "                layers.Dense(embed_dim),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def causal_attention_mask(self, batch_size, n_dest, n_src, dtype):\n",
    "        \"\"\"Masks the upper half of the dot product matrix in self attention.\n",
    "\n",
    "        This prevents flow of information from future tokens to current token.\n",
    "        1's in the lower triangle, counting from the lower right corner.\n",
    "        \"\"\"\n",
    "        i = tf.range(n_dest)[:, None]\n",
    "        j = tf.range(n_src)\n",
    "        m = i >= j - n_src + n_dest\n",
    "        mask = tf.cast(m, dtype)\n",
    "        mask = tf.reshape(mask, [1, n_dest, n_src])\n",
    "        mult = tf.concat(\n",
    "            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)], 0\n",
    "        )\n",
    "        return tf.tile(mask, mult)\n",
    "\n",
    "    def call(self, enc_out, target):\n",
    "        input_shape = tf.shape(target)\n",
    "        batch_size = input_shape[0]\n",
    "        seq_len = input_shape[1]\n",
    "        causal_mask = self.causal_attention_mask(batch_size, seq_len, seq_len, tf.bool)\n",
    "        target_att = self.self_att(target, target, attention_mask=causal_mask)\n",
    "        target_norm = self.layernorm1(target + self.self_dropout(target_att))\n",
    "        enc_out = self.enc_att(target_norm, enc_out)\n",
    "        enc_out_norm = self.layernorm2(self.enc_dropout(enc_out) + target_norm)\n",
    "        ffn_out = self.ffn(enc_out_norm)\n",
    "        ffn_out_norm = self.layernorm3(enc_out_norm + self.ffn_dropout(ffn_out))\n",
    "        return ffn_out_norm\n",
    "\n",
    "\n",
    "class Transformer(keras.Model):\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_hid=64,\n",
    "            num_head=2,\n",
    "            num_feed_forward=128,\n",
    "            source_maxlen=100,\n",
    "            target_maxlen=100,\n",
    "            num_layers_enc=4,\n",
    "            num_layers_dec=1,\n",
    "            num_classes=10,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.loss_metric = keras.metrics.Mean(name=\"loss\")\n",
    "        self.num_layers_enc = num_layers_enc\n",
    "        self.num_layers_dec = num_layers_dec\n",
    "        self.target_maxlen = target_maxlen\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.enc_input = SpeechFeatureEmbedding(num_hid=num_hid, maxlen=source_maxlen)\n",
    "        self.dec_input = TokenEmbedding(\n",
    "            num_vocab=num_classes, maxlen=target_maxlen, num_hid=num_hid\n",
    "        )\n",
    "\n",
    "        self.encoder = keras.Sequential(\n",
    "            [self.enc_input]\n",
    "            + [\n",
    "                TransformerEncoder(num_hid, num_head, num_feed_forward)\n",
    "                for _ in range(num_layers_enc)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        for i in range(num_layers_dec):\n",
    "            setattr(\n",
    "                self,\n",
    "                f\"dec_layer_{i}\",\n",
    "                TransformerDecoder(num_hid, num_head, num_feed_forward),\n",
    "            )\n",
    "\n",
    "        self.classifier = layers.Dense(num_classes)\n",
    "\n",
    "    def decode(self, enc_out, target):\n",
    "        y = self.dec_input(target)\n",
    "        for i in range(self.num_layers_dec):\n",
    "            y = getattr(self, f\"dec_layer_{i}\")(enc_out, y)\n",
    "        return y\n",
    "\n",
    "    def call(self, inputs):\n",
    "        source = inputs[0]\n",
    "        target = inputs[1]\n",
    "        x = self.encoder(source)\n",
    "        y = self.decode(x, target)\n",
    "        return self.classifier(y)\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.loss_metric]\n",
    "\n",
    "    def train_step(self, batch):\n",
    "        \"\"\"Processes one batch inside model.fit().\"\"\"\n",
    "        source = batch[\"source\"]\n",
    "        target = batch[\"target\"]\n",
    "        print(\"source : \" + str(source))\n",
    "        print(\"target : \" + str(target))\n",
    "        dec_input = target[:, :-1]\n",
    "        dec_target = target[:, 1:]\n",
    "        with tf.GradientTape() as tape:\n",
    "            preds = self([source, dec_input])\n",
    "            one_hot = tf.one_hot(dec_target, depth=self.num_classes)\n",
    "            mask = tf.math.logical_not(tf.math.equal(dec_target, 0))\n",
    "            loss = self.compiled_loss(one_hot, preds, sample_weight=mask)\n",
    "        trainable_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "        self.loss_metric.update_state(loss)\n",
    "        return {\"loss\": self.loss_metric.result()}\n",
    "\n",
    "    def test_step(self, batch):\n",
    "        source = batch[\"source\"]\n",
    "        target = batch[\"target\"]\n",
    "        dec_input = target[:, :-1]\n",
    "        dec_target = target[:, 1:]\n",
    "        preds = self([source, dec_input])\n",
    "        one_hot = tf.one_hot(dec_target, depth=self.num_classes)\n",
    "        mask = tf.math.logical_not(tf.math.equal(dec_target, 0))\n",
    "        loss = self.compiled_loss(one_hot, preds, sample_weight=mask)\n",
    "        self.loss_metric.update_state(loss)\n",
    "        return {\"loss\": self.loss_metric.result()}\n",
    "\n",
    "    def generate(self, source, target_start_token_idx):\n",
    "        \"\"\"Performs inference over one batch of inputs using greedy decoding.\"\"\"\n",
    "        bs = tf.shape(source)[0]\n",
    "        enc = self.encoder(source)\n",
    "        dec_input = tf.ones((bs, 1), dtype=tf.int32) * target_start_token_idx\n",
    "        dec_logits = []\n",
    "        for i in range(self.target_maxlen - 1):\n",
    "            dec_out = self.decode(enc, dec_input)\n",
    "            logits = self.classifier(dec_out)\n",
    "            logits = tf.argmax(logits, axis=-1, output_type=tf.int32)\n",
    "            last_logit = tf.expand_dims(logits[:, -1], axis=-1)\n",
    "            dec_logits.append(last_logit)\n",
    "            dec_input = tf.concat([dec_input, last_logit], axis=-1)\n",
    "        return dec_input\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "from MapCreator.Utils.trainingMapParser import get_paths\n",
    "from MapCreator.IA.Transformers.Model import *\n",
    "from MapCreator.IA.Transformers.Dataset import *\n",
    "\n",
    "\n",
    "class DisplayOutputs(keras.callbacks.Callback):\n",
    "    def __init__(\n",
    "            self, batch, idx_to_token, target_start_token_idx=27, target_end_token_idx=28\n",
    "    ):\n",
    "        \"\"\"Displays a batch of outputs after every epoch\n",
    "\n",
    "        Args:\n",
    "            batch: A test batch containing the keys \"source\" and \"target\"\n",
    "            idx_to_token: A List containing the vocabulary tokens corresponding to their indices\n",
    "            target_start_token_idx: A start token index in the target vocabulary\n",
    "            target_end_token_idx: An end token index in the target vocabulary\n",
    "        \"\"\"\n",
    "        self.batch = batch\n",
    "        self.target_start_token_idx = target_start_token_idx\n",
    "        self.target_end_token_idx = target_end_token_idx\n",
    "        self.idx_to_char = idx_to_token\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch % 5 != 0:\n",
    "            return\n",
    "        source = self.batch[\"source\"]\n",
    "        target = self.batch[\"target\"].numpy()\n",
    "        bs = tf.shape(source)[0]\n",
    "        preds = self.model.generate(source, self.target_start_token_idx)\n",
    "        preds = preds.numpy()\n",
    "        for i in range(bs):\n",
    "            target_text = \"\".join([self.idx_to_char[_] for _ in target[i, :]])\n",
    "            prediction = \"\"\n",
    "            for idx in preds[i, :]:\n",
    "                prediction += self.idx_to_char[idx]\n",
    "                if idx == self.target_end_token_idx:\n",
    "                    break\n",
    "            print(f\"target:     {target_text.replace('-', '')}\")\n",
    "            print(f\"prediction: {prediction}\\n\")\n",
    "\n",
    "\n",
    "class CustomSchedule(keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(\n",
    "            self,\n",
    "            init_lr=0.00001,\n",
    "            lr_after_warmup=0.001,\n",
    "            final_lr=0.00001,\n",
    "            warmup_epochs=15,\n",
    "            decay_epochs=85,\n",
    "            steps_per_epoch=203,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.init_lr = init_lr\n",
    "        self.lr_after_warmup = lr_after_warmup\n",
    "        self.final_lr = final_lr\n",
    "        self.warmup_epochs = warmup_epochs\n",
    "        self.decay_epochs = decay_epochs\n",
    "        self.steps_per_epoch = steps_per_epoch\n",
    "\n",
    "    def calculate_lr(self, epoch):\n",
    "        \"\"\" linear warm up - linear decay \"\"\"\n",
    "        warmup_lr = (\n",
    "                self.init_lr\n",
    "                + ((self.lr_after_warmup - self.init_lr) / (self.warmup_epochs - 1)) * epoch\n",
    "        )\n",
    "        decay_lr = tf.math.maximum(\n",
    "            self.final_lr,\n",
    "            self.lr_after_warmup\n",
    "            - (epoch - self.warmup_epochs)\n",
    "            * (self.lr_after_warmup - self.final_lr)\n",
    "            / self.decay_epochs,\n",
    "        )\n",
    "        return tf.math.minimum(warmup_lr, decay_lr)\n",
    "\n",
    "    def __call__(self, step):\n",
    "        epoch = step // self.steps_per_epoch\n",
    "        return self.calculate_lr(epoch)\n",
    "\n",
    "\n",
    "max_target_len = 13*120\n",
    "base_path = \"C:/Users/Lysandre/Documents/GitHub/OsuMapCreator/MapCreator/datasets\"\n",
    "paths = get_paths(os.path.join(base_path, \"maps\"))\n",
    "data = load_beatmaps_and_musics(paths, max_nb_musics=500)\n",
    "split = int(len(data) * 0.99)\n",
    "train_data = data[:split]\n",
    "test_data = data[split:]\n",
    "ds = create_text_and_audio_ds(train_data, bs=64)\n",
    "val_ds = create_text_and_audio_ds(test_data, bs=4)\n",
    "batch = next(iter(val_ds))\n",
    "\n",
    "# The vocabulary to convert predicted indices into characters\n",
    "\"\"\"display_cb = DisplayOutputs(\n",
    "    batch, idx_to_char, target_start_token_idx=2, target_end_token_idx=3\n",
    ")  # set the arguments as per vocabulary index for '<' and '>'\"\"\"\n",
    "\n",
    "model = Transformer(\n",
    "    num_hid=200,\n",
    "    num_head=2,\n",
    "    num_feed_forward=400,\n",
    "    target_maxlen=max_target_len,\n",
    "    num_layers_enc=4,\n",
    "    num_layers_dec=1,\n",
    "    num_classes=10003,\n",
    ")\n",
    "loss_fn = tf.keras.losses.MeanSquaredError(\n",
    ")\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=1e-4)\n",
    "model.compile(optimizer=optimizer, loss=loss_fn)\n",
    "\n",
    "history = model.fit(ds, validation_data=val_ds, epochs=1)\n",
    "import os\n",
    "from MapCreator.Utils.trainingMapParser import get_paths\n",
    "from MapCreator.IA.Transformers.Model import *\n",
    "from MapCreator.IA.Transformers.Dataset import *\n",
    "\n",
    "\n",
    "class DisplayOutputs(keras.callbacks.Callback):\n",
    "    def __init__(\n",
    "            self, batch, idx_to_token, target_start_token_idx=27, target_end_token_idx=28\n",
    "    ):\n",
    "        \"\"\"Displays a batch of outputs after every epoch\n",
    "\n",
    "        Args:\n",
    "            batch: A test batch containing the keys \"source\" and \"target\"\n",
    "            idx_to_token: A List containing the vocabulary tokens corresponding to their indices\n",
    "            target_start_token_idx: A start token index in the target vocabulary\n",
    "            target_end_token_idx: An end token index in the target vocabulary\n",
    "        \"\"\"\n",
    "        self.batch = batch\n",
    "        self.target_start_token_idx = target_start_token_idx\n",
    "        self.target_end_token_idx = target_end_token_idx\n",
    "        self.idx_to_char = idx_to_token\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch % 5 != 0:\n",
    "            return\n",
    "        source = self.batch[\"source\"]\n",
    "        target = self.batch[\"target\"].numpy()\n",
    "        bs = tf.shape(source)[0]\n",
    "        preds = self.model.generate(source, self.target_start_token_idx)\n",
    "        preds = preds.numpy()\n",
    "        for i in range(bs):\n",
    "            target_text = \"\".join([self.idx_to_char[_] for _ in target[i, :]])\n",
    "            prediction = \"\"\n",
    "            for idx in preds[i, :]:\n",
    "                prediction += self.idx_to_char[idx]\n",
    "                if idx == self.target_end_token_idx:\n",
    "                    break\n",
    "            print(f\"target:     {target_text.replace('-', '')}\")\n",
    "            print(f\"prediction: {prediction}\\n\")\n",
    "\n",
    "\n",
    "class CustomSchedule(keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(\n",
    "            self,\n",
    "            init_lr=0.00001,\n",
    "            lr_after_warmup=0.001,\n",
    "            final_lr=0.00001,\n",
    "            warmup_epochs=15,\n",
    "            decay_epochs=85,\n",
    "            steps_per_epoch=203,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.init_lr = init_lr\n",
    "        self.lr_after_warmup = lr_after_warmup\n",
    "        self.final_lr = final_lr\n",
    "        self.warmup_epochs = warmup_epochs\n",
    "        self.decay_epochs = decay_epochs\n",
    "        self.steps_per_epoch = steps_per_epoch\n",
    "\n",
    "    def calculate_lr(self, epoch):\n",
    "        \"\"\" linear warm up - linear decay \"\"\"\n",
    "        warmup_lr = (\n",
    "                self.init_lr\n",
    "                + ((self.lr_after_warmup - self.init_lr) / (self.warmup_epochs - 1)) * epoch\n",
    "        )\n",
    "        decay_lr = tf.math.maximum(\n",
    "            self.final_lr,\n",
    "            self.lr_after_warmup\n",
    "            - (epoch - self.warmup_epochs)\n",
    "            * (self.lr_after_warmup - self.final_lr)\n",
    "            / self.decay_epochs,\n",
    "        )\n",
    "        return tf.math.minimum(warmup_lr, decay_lr)\n",
    "\n",
    "    def __call__(self, step):\n",
    "        epoch = step // self.steps_per_epoch\n",
    "        return self.calculate_lr(epoch)\n",
    "\n",
    "\n",
    "max_target_len = 13*120\n",
    "base_path = \"C:/Users/Lysandre/Documents/GitHub/OsuMapCreator/MapCreator/datasets\"\n",
    "paths = get_paths(os.path.join(base_path, \"maps\"))\n",
    "data = load_beatmaps_and_musics(paths, max_nb_musics=500)\n",
    "split = int(len(data) * 0.99)\n",
    "train_data = data[:split]\n",
    "test_data = data[split:]\n",
    "ds = create_text_and_audio_ds(train_data, bs=64)\n",
    "val_ds = create_text_and_audio_ds(test_data, bs=4)\n",
    "batch = next(iter(val_ds))\n",
    "\n",
    "# The vocabulary to convert predicted indices into characters\n",
    "\"\"\"display_cb = DisplayOutputs(\n",
    "    batch, idx_to_char, target_start_token_idx=2, target_end_token_idx=3\n",
    ")  # set the arguments as per vocabulary index for '<' and '>'\"\"\"\n",
    "\n",
    "model = Transformer(\n",
    "    num_hid=200,\n",
    "    num_head=2,\n",
    "    num_feed_forward=400,\n",
    "    target_maxlen=max_target_len,\n",
    "    num_layers_enc=4,\n",
    "    num_layers_dec=1,\n",
    "    num_classes=10003,\n",
    ")\n",
    "loss_fn = tf.keras.losses.MeanSquaredError(\n",
    ")\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=1e-4)\n",
    "model.compile(optimizer=optimizer, loss=loss_fn)\n",
    "\n",
    "history = model.fit(ds, validation_data=val_ds, epochs=1)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from enum import Enum\n",
    "from typing import List, Optional\n",
    "import abc\n",
    "\n",
    "\n",
    "class SectionName(Enum):\n",
    "    General = \"[General]\"\n",
    "    Editor = \"[Editor]\"\n",
    "    Metadata = \"[Metadata]\"\n",
    "    Difficulty = \"[Difficulty]\"\n",
    "    Events = \"[Events]\"\n",
    "    TimingPoints = \"[TimingPoints]\"\n",
    "    Colours = \"[Colours]\"\n",
    "    HitObjects = \"[HitObjects]\"\n",
    "\n",
    "\n",
    "class Section:\n",
    "\n",
    "    def value(self, value):\n",
    "        if value.strip().isnumeric():\n",
    "            return int(value)\n",
    "        else:\n",
    "            try:\n",
    "                return float(value)\n",
    "            except ValueError:\n",
    "                return value\n",
    "\n",
    "    def parse_line(self, line: str):\n",
    "        ...\n",
    "\n",
    "\n",
    "class HitSample:\n",
    "    normalSet: int = 0  # SampleSet\n",
    "    additionSet: int = 0  # SampleSet\n",
    "    index: int = 0\n",
    "    volume: int = 0\n",
    "    filename: Optional[str] = None\n",
    "\n",
    "    def set(self, normalSet: int, additionSet: int, index: int, volume: int, filename: Optional[str] = \"\"):\n",
    "        self.normalSet = normalSet\n",
    "        self.additionSet = additionSet\n",
    "        self.index = index\n",
    "        self.volume = volume\n",
    "        self.filename = filename\n",
    "\n",
    "    def __str__(self):\n",
    "        if self.filename is not None:\n",
    "            return str(f\"{self.normalSet}:{self.additionSet}:{self.index}:{self.volume}:{self.filename}:\")\n",
    "        else:\n",
    "            return str(f\"{self.normalSet}:{self.additionSet}:{self.index}:{self.volume}:\")\n",
    "\n",
    "\n",
    "class General(Section):\n",
    "\n",
    "    def __init__(self,\n",
    "                 AudioFilename: Optional[str] = None,\n",
    "                 AudioLeadIn: Optional[int] = 0,\n",
    "                 AudioHash: Optional[str] = None,\n",
    "                 PreviewTime: Optional[int] = -1,\n",
    "                 Countdown: Optional[int] = 1,\n",
    "                 SampleSet: Optional[str] = \"Normal\",  # SampleSet.Normal.value\n",
    "                 StackLeniency: Optional[float] = 0.7,\n",
    "                 Mode: Optional[int] = 0,\n",
    "                 LetterboxInBreaks: Optional[int] = 0,\n",
    "                 StoryFireInFront: Optional[int] = 1,\n",
    "                 UseSkinSprites: Optional[int] = 0,\n",
    "                 AlwaysShowPlayfield: Optional[int] = 0,\n",
    "                 OverlayPosition: Optional[str] = \"NoChange\",\n",
    "                 SkinPreference: Optional[str] = None,\n",
    "                 EpilepsyWarning: Optional[int] = 0,\n",
    "                 CountdownOffset: Optional[int] = 0,\n",
    "                 SpecialStyle: Optional[int] = 0,\n",
    "                 WidescreenStoryboard: Optional[int] = 0,\n",
    "                 SamplesMatchPlaybackRate: Optional[int] = 0):\n",
    "        self.AudioFilename = AudioFilename\n",
    "        self.OverlayPosition = OverlayPosition\n",
    "        self.EpilepsyWarning = EpilepsyWarning\n",
    "        self.SpecialStyle = SpecialStyle\n",
    "        self.SamplesMatchPlaybackRate = SamplesMatchPlaybackRate\n",
    "        self.WidescreenStoryboard = WidescreenStoryboard\n",
    "        self.CountdownOffset = CountdownOffset\n",
    "        self.SkinPreference = SkinPreference\n",
    "        self.UseSkinSprites = UseSkinSprites\n",
    "        self.AlwaysShowPlayfield = AlwaysShowPlayfield\n",
    "        self.LetterboxInBreaks = LetterboxInBreaks\n",
    "        self.StoryFireInFront = StoryFireInFront\n",
    "        self.Mode = Mode\n",
    "        self.StackLeniency = StackLeniency\n",
    "        self.SampleSet = SampleSet\n",
    "        self.Countdown = Countdown\n",
    "        self.PreviewTime = PreviewTime\n",
    "        self.AudioLeadIn = AudioLeadIn\n",
    "        self.AudioHash = AudioHash\n",
    "\n",
    "    def parse_line(self, line: str):\n",
    "        members = line.split(':')\n",
    "        self.__setattr__(members[0], self.value(members[1]))\n",
    "\n",
    "\n",
    "class Editor(Section):\n",
    "    def __init__(self,\n",
    "                 Bookmarks: Optional[List[int]] = None,\n",
    "                 DistanceSpacing: Optional[float] = None,\n",
    "                 BeatDivisor: Optional[int] = None,\n",
    "                 GridSize: Optional[int] = None,\n",
    "                 TimelineZoom: Optional[float] = None):\n",
    "        self.GridSize = GridSize\n",
    "        self.BeatDivisor = BeatDivisor\n",
    "        self.DistanceSpacing = DistanceSpacing\n",
    "        self.Bookmarks = Bookmarks\n",
    "        self.TimelineZoom = TimelineZoom\n",
    "\n",
    "    def parse_line(self, line: str):\n",
    "        members = line.split(':')\n",
    "        if members[0] == \"Bookmarks\":\n",
    "            self.Bookmarks = [self.value(x) for x in members[1].split(\",\")]\n",
    "        else:\n",
    "            self.__setattr__(members[0], self.value(members[1]))\n",
    "\n",
    "\n",
    "class Metadata(Section):\n",
    "    def __init__(self,\n",
    "                 Title: Optional[str] = None,\n",
    "                 TitleUnicode: Optional[str] = None,\n",
    "                 Artist: Optional[str] = None,\n",
    "                 ArtistUnicode: Optional[str] = None,\n",
    "                 Creator: Optional[str] = None,\n",
    "                 Version: Optional[str] = None,\n",
    "                 Source: Optional[str] = None,\n",
    "                 Tags: Optional[List[str]] = None,\n",
    "                 BeatmapID: Optional[int] = None,\n",
    "                 BeatmapSetID: Optional[int] = None):\n",
    "\n",
    "        self.Tags = Tags\n",
    "        self.BeatmapSetID = BeatmapSetID\n",
    "        self.BeatmapID = BeatmapID\n",
    "        self.Source = Source\n",
    "        self.Version = Version\n",
    "        self.Creator = Creator\n",
    "        self.ArtistUnicode = ArtistUnicode\n",
    "        self.Artist = Artist\n",
    "        self.TitleUnicode = TitleUnicode\n",
    "        self.Title = Title\n",
    "\n",
    "    def parse_line(self, line: str):\n",
    "        members = line.split(':')\n",
    "        if members[0] == \"Tags\":\n",
    "            self.Tags = [x for x in members[1].split(\" \")]\n",
    "        else:\n",
    "            self.__setattr__(members[0], self.value(members[1]))\n",
    "\n",
    "\n",
    "class Difficulty(Section):\n",
    "    HPDrainRate: float\n",
    "    CircleSize: float\n",
    "    OverallDifficulty: float\n",
    "    ApproachRate: float\n",
    "    SliderMultiplier: float\n",
    "    SliderTickRate: float\n",
    "\n",
    "    def parse_line(self, line: str):\n",
    "        members = line.split(':')\n",
    "        self.__setattr__(members[0], self.value(members[1]))\n",
    "\n",
    "\n",
    "class EventParams:\n",
    "    pass\n",
    "\n",
    "\n",
    "class Event(Section):\n",
    "    eventType: str\n",
    "    startTime: int\n",
    "    eventParams: List[EventParams]\n",
    "\n",
    "\n",
    "class Background(EventParams):\n",
    "    filename: str\n",
    "    xOffset: int\n",
    "    yOffset: int\n",
    "\n",
    "\n",
    "class Video(EventParams):\n",
    "    Video: 1\n",
    "    startTime: int\n",
    "    filename: str\n",
    "    xOffset: int\n",
    "    yOffset: int\n",
    "\n",
    "\n",
    "class Pause(EventParams):\n",
    "    # 2:Break TODO check wiki because sintaxe is strange\n",
    "    Break: 2\n",
    "    startTime: int\n",
    "    endTime: int\n",
    "\n",
    "\n",
    "#  TODO\n",
    "class Storyboard(EventParams):\n",
    "    pass\n",
    "\n",
    "\n",
    "class TimingPoint(Section):\n",
    "    time: int\n",
    "    beatLength: float\n",
    "    meter: int\n",
    "    sampleSet: int = 1  # SampleSet = SampleSet.Normal.value\n",
    "    sampleIndex: int = 0\n",
    "    volume: int = 1\n",
    "    uninherited: int\n",
    "    effects: int = 0  # Effect = None\n",
    "    bpm: int\n",
    "\n",
    "    def parse_line(self, line: str):\n",
    "        members = line.split(\",\")\n",
    "        self.time = self.value(members[0])\n",
    "        self.beatLength = self.value(members[1])\n",
    "        self.meter = self.value(members[2])\n",
    "        self.sampleSet = self.value(members[3])\n",
    "        self.sampleIndex = self.value(members[4])\n",
    "        self.volume = self.value(members[5])\n",
    "        self.uninherited = self.value(members[6])\n",
    "        self.effects = self.value(members[7])\n",
    "        self.calculate_bpm()\n",
    "\n",
    "    def calculate_bpm(self):\n",
    "        self.bpm = round(60000 / self.beatLength)\n",
    "\n",
    "\n",
    "# TODO check wiki for colours\n",
    "class ColourObject(Section):\n",
    "    Combo: int\n",
    "    color: List[int]\n",
    "\n",
    "    # SliderTrackOverride\n",
    "    # SliderBorder\n",
    "    def parse_line(self, line):\n",
    "        pass\n",
    "\n",
    "\n",
    "class HitObject(Section):\n",
    "    # x: int\n",
    "    # y: int\n",
    "    # time: int\n",
    "    # type: int\n",
    "    # hitSound: int = 0\n",
    "    # hitSample: str  # Optional[HitSample]\n",
    "\n",
    "    def __init__(self,\n",
    "                 x: Optional[int] = 0,\n",
    "                 y: Optional[int] = 0,\n",
    "                 time: Optional[int] = 0,\n",
    "                 type: Optional[int] = 0,  # Type\n",
    "                 hitSound: Optional[int] = 0,\n",
    "                 hitSample: Optional[str] = None):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.time = time\n",
    "        self.type = type\n",
    "        self.hitSound = hitSound\n",
    "        if hitSample is None:\n",
    "            self.hitSample = HitSample().__str__()\n",
    "        else:\n",
    "            self.hitSample = hitSample\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"{self.x},{self.y},{self.time},{self.type},{self.hitSound},{self.hitSample}\"\n",
    "\n",
    "    def get_hit_sample(self, line) -> str:\n",
    "        if self.has_hit_sample(line):\n",
    "            return line\n",
    "        return \"0:0:0:0:0:\"\n",
    "\n",
    "    def has_hit_sample(self, line) -> bool:\n",
    "        if type(line) == int or type(line) == float:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "\n",
    "    def get(self, _type):\n",
    "        return self.__dict__.get(str(_type))\n",
    "\n",
    "    def get_type(self, _type):\n",
    "        if _type & 1:\n",
    "            print(\"circle\")\n",
    "        elif _type & 2:\n",
    "            print(\"slider\")\n",
    "        elif _type & 8:\n",
    "            print(\"spinner\")\n",
    "        # elif _type & 128:\n",
    "        #     print(\"mania\")\n",
    "        else:\n",
    "            print(\"unknown type:\", _type)\n",
    "\n",
    "    def is_slider(self, _type) -> bool:\n",
    "        if _type & 2:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def is_spinner(self, _type) -> bool:\n",
    "        if _type & 8:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def is_circle(self, _type) -> bool:\n",
    "        if _type & 1:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "\n",
    "class Cercle(HitObject):\n",
    "\n",
    "    def __init__(self,\n",
    "                 x: Optional[int] = 0,\n",
    "                 y: Optional[int] = 0,\n",
    "                 time: Optional[int] = 0,\n",
    "                 type: Optional[int] = 0,  # Type\n",
    "                 hitSound: Optional[int] = 0,\n",
    "                 hitSample: Optional[str] = None):\n",
    "        super().__init__(x, y, time, type, hitSound, hitSample)\n",
    "\n",
    "    def parse_line(self, line):\n",
    "        members = line.split(\",\")\n",
    "        self.x = self.value(members[0])\n",
    "        self.y = self.value(members[1])\n",
    "        self.time = self.value(members[2])\n",
    "        self.type = self.value(members[3])\n",
    "        self.hitSound = self.value(members[4])\n",
    "        self.hitSample = self.get_hit_sample(self.value(members[-1]))\n",
    "\n",
    "\n",
    "class Spinner(HitObject):\n",
    "    endTime: int\n",
    "\n",
    "    def parse_line(self, line):\n",
    "        members = line.split(\",\")\n",
    "        self.x = self.value(members[0])\n",
    "        self.y = self.value(members[1])\n",
    "        self.time = self.value(members[2])\n",
    "        self.type = self.value(members[3])\n",
    "        self.hitSound = self.value(members[4])\n",
    "        self.endTime = self.value(members[5])\n",
    "\n",
    "        self.hitSample = self.get_hit_sample(self.value(members[-1]))\n",
    "\n",
    "\n",
    "class CurvePoint:\n",
    "    x: int\n",
    "    y: int\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"{self.x}:{self.y}\"\n",
    "\n",
    "\n",
    "class Slider(HitObject):\n",
    "    curveType: str\n",
    "    curvePoints: List[CurvePoint]\n",
    "    slides: int\n",
    "    length: float\n",
    "    edgeSounds: str\n",
    "    edgeSets: str\n",
    "\n",
    "    def parse_line(self, line):\n",
    "        members = line.split(\",\")\n",
    "        self.x = self.value(members[0])\n",
    "        self.y = self.value(members[1])\n",
    "        self.time = self.value(members[2])\n",
    "        self.type = self.value(members[3])\n",
    "        self.hitSound = self.value(members[4])\n",
    "\n",
    "        # Parse slider points\n",
    "        points = (members[5] or '').split('|')\n",
    "        self.curveType = points[0]\n",
    "        self.curvePoints = []\n",
    "        if len(points):\n",
    "            for i in range(1, len(points)):\n",
    "                coordinates = points[i].split(':')\n",
    "                curve_point = CurvePoint()\n",
    "                curve_point.x = self.value(coordinates[0])\n",
    "                curve_point.y = self.value(coordinates[1])\n",
    "                # self.curvePoints.append(curve_point)\n",
    "                self.curvePoints.append(curve_point.__str__())\n",
    "\n",
    "        # Parse repeat slides bumber & length\n",
    "        self.slides = int(members[6])\n",
    "        self.length = int(round(float(members[7])))\n",
    "\n",
    "        # Parse edgeSounds\n",
    "        if len(members) > 9:\n",
    "            if members[8]:\n",
    "                self.edgeSounds = members[8]\n",
    "\n",
    "            # Parse edgeSets\n",
    "            if members[9]:\n",
    "                self.edgeSets = members[9]\n",
    "\n",
    "        self.hitSample = self.get_hit_sample(self.value(members[-1]))\n"
   ],
   "metadata": {
    "id": "qk5iTkxTnFZ7"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import codecs\n",
    "import os\n",
    "import re\n",
    "from typing import List\n",
    "\n",
    "from MapCreator.Utils.models.models import General, Editor, Metadata, Difficulty, Event, TimingPoint, ColourSection, \\\n",
    "    HitObject, SectionName, Slider, Spinner, Cercle\n",
    "\n",
    "\n",
    "class Parser:\n",
    "    def __init__(self):\n",
    "        self.file_format = \"\"\n",
    "        self.general = General()\n",
    "        self.editor = Editor()\n",
    "        self.metadata = Metadata()\n",
    "        self.difficulty = Difficulty()\n",
    "        self.events: List[Event] = []\n",
    "        self.timing_points: List[TimingPoint] = []\n",
    "        self.colours: List[ColourSection] = []\n",
    "        self.hit_objects: List[HitObject] = []\n",
    "\n",
    "        self.osu_section = \"\"\n",
    "\n",
    "    def parse_hit_object_type(self, line):\n",
    "        _type = int(line.split(\",\")[3].strip())\n",
    "        # https://osu.ppy.sh/wiki/fr/Client/File_formats/Osu_%28file_format%29#type\n",
    "        # convert in bit\n",
    "        # 0: Cercle\n",
    "        # 1: Slider\n",
    "        # 3:Spinner\n",
    "        # 7 osu mania\n",
    "        if _type & 1:\n",
    "            cercle = Cercle()\n",
    "            cercle.parse_line(line)\n",
    "            return cercle\n",
    "        elif _type & 2:\n",
    "            slider = Slider()\n",
    "            slider.parse_line(line)\n",
    "            return slider\n",
    "        elif _type & 8:\n",
    "            spinner = Spinner()\n",
    "            spinner.parse_line(line)\n",
    "            return spinner\n",
    "        # elif _type & 128:\n",
    "        #     print(\"mania\")\n",
    "        else:\n",
    "            cercle = Cercle()\n",
    "            cercle.parse_line(line)\n",
    "            print(\"unknown type:\", _type)\n",
    "            return cercle\n",
    "\n",
    "    def parse_line(self, line: str):\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            return\n",
    "\n",
    "        match = re.search(r\"\\[(.*?)\\]\", line)\n",
    "        if match:\n",
    "            self.osu_section = match.group(0)\n",
    "            return\n",
    "        match = re.match('^osu file format (v[0-9]+)$', line)\n",
    "        if match:\n",
    "            # self.file_format = line\n",
    "            self.file_format = match.group(1)\n",
    "            return\n",
    "        if self.osu_section == SectionName.General.value:\n",
    "            self.general.parse_line(line)\n",
    "        elif self.osu_section == SectionName.Editor.value:\n",
    "            self.editor.parse_line(line)\n",
    "        elif self.osu_section == SectionName.Metadata.value:\n",
    "            self.metadata.parse_line(line)\n",
    "        elif self.osu_section == SectionName.Difficulty.value:\n",
    "            self.difficulty.parse_line(line)\n",
    "        # elif self.osu_section == SectionName.Events.name:\n",
    "        #     self.events_section.append(line)\n",
    "        elif self.osu_section == SectionName.TimingPoints.value:\n",
    "            timing_point = TimingPoint()\n",
    "            timing_point.parse_line(line)\n",
    "            self.timing_points.append(timing_point)\n",
    "        # elif self.osu_section == SectionName.Colours.name:\n",
    "        #     self.colours_section.append(line)\n",
    "        elif self.osu_section == SectionName.HitObjects.value:\n",
    "            hit_obj = self.parse_hit_object_type(line)\n",
    "            self.hit_objects.append(hit_obj)\n",
    "\n",
    "    def parse_file(self, file):\n",
    "        if os.path.isfile(file):\n",
    "            with codecs.open(file, 'r', encoding=\"utf-8\") as file:\n",
    "                line = file.readline()\n",
    "                while line:\n",
    "                    self.parse_line(line)\n",
    "                    line = file.readline()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    PATH = \"C:/Users/Lysandre/Documents/GitHub/OsuMapCreator/MapCreator/datasets/maps/67565 DragonForce - Valley of the \" \\\n",
    "           \"Damned/DragonForce - Valley of the Damned (Kayne) [Apocalypse].osu\"\n",
    "    parser = Parser()\n",
    "    parser.parse_file(PATH)\n",
    "    # print(parser.timing_points[0].time)\n",
    "    for o in parser.hit_objects:\n",
    "        if isinstance(o, Cercle):\n",
    "            print(\"true\")\n",
    "        else:\n",
    "            print(\"false\")\n",
    "    # for obj in parser.hit_objects:\n",
    "    #     # print(type(obj),obj.__dict__)\n",
    "    #     print(obj.__dict__)\n"
   ],
   "metadata": {
    "id": "dDM4FtjzmXFS"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import os.path\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from MapCreator.Utils.models.models import Spinner, Cercle, Slider, HitObject\n",
    "from MapCreator.Utils.parser import Parser\n",
    "from MapCreator.Utils.audio import load_melspectrogram\n",
    "\n",
    "\n",
    "def scale_beatmap(hitpoints: List[HitObject]):\n",
    "    # we take 7min30s for each beatmap\n",
    "    duration = 7.739984882842026 * 60\n",
    "    new_hitpoints = []\n",
    "    for h in hitpoints:\n",
    "        if h.time <= duration * 1000:\n",
    "            new_hitpoints.append(h)\n",
    "    # hitpoints = [x for x in hitpoints if x[2] <= duration * 1000]\n",
    "    return new_hitpoints\n",
    "\n",
    "\n",
    "def load_beatmap_attributes(path, max_hit_object=4000):\n",
    "    cols = [\"x\", \"y\", \"time\", \"type\", \"endtime\", \"x2\", \"y2\", \"x3\", \"y3\", \"x4\", \"y4\", \"slide\", \"length\"]\n",
    "    parser = Parser()\n",
    "    parser.parse_file(path)\n",
    "\n",
    "    hitpoints = scale_beatmap(parser.hit_objects)\n",
    "\n",
    "    if max_hit_object is None:\n",
    "        max_hit_object = len(hitpoints)\n",
    "    data = np.zeros((13, max_hit_object), dtype=int)\n",
    "\n",
    "    for (i, o) in enumerate(hitpoints):\n",
    "\n",
    "        if i < max_hit_object:\n",
    "\n",
    "            data[0][i] = o.x\n",
    "            data[1][i] = o.y\n",
    "            data[2][i] = o.time\n",
    "            data[3][i] = o.type\n",
    "\n",
    "            if isinstance(o, Cercle):\n",
    "                pass\n",
    "            elif isinstance(o, Spinner):\n",
    "                data[4][i] = o.endTime\n",
    "            elif isinstance(o, Slider):\n",
    "                data[5][i] = o.curvePoints[0].x\n",
    "                data[6][i] = o.curvePoints[0].y\n",
    "\n",
    "                if len(o.curvePoints) > 1:\n",
    "                    data[7][i] = o.curvePoints[1].x\n",
    "                    data[8][i] = o.curvePoints[1].y\n",
    "\n",
    "                if len(o.curvePoints) > 2:\n",
    "                    data[9][i] = o.curvePoints[2].x\n",
    "                    data[10][i] = o.curvePoints[2].y\n",
    "\n",
    "                data[11][i] = o.slides\n",
    "                data[12][i] = o.length\n",
    "\n",
    "    return data, parser.difficulty.OverallDifficulty\n",
    "\n",
    "\n",
    "def load_beatmaps_and_spectrograms(paths: List, max=1000):\n",
    "    arr = []\n",
    "    diff = []\n",
    "    spectrograms = []\n",
    "    for i, path in enumerate(paths):\n",
    "        if max and i >= max:\n",
    "            break\n",
    "        spectrogram = path_to_audio(path[1])\n",
    "        for beatmap in path[0]:\n",
    "            df_temp, difficulty = load_beatmap_attributes(beatmap)\n",
    "            df_temp = df_temp.transpose()\n",
    "            arr.append(df_temp)\n",
    "            diff.append(difficulty)\n",
    "            spectrograms.append(spectrogram)\n",
    "    diff = np.array(diff, dtype=float)\n",
    "    return arr, spectrograms, diff\n",
    "\n",
    "\n",
    "def normalize(img):\n",
    "    '''\n",
    "    Normalizes an array\n",
    "    (subtract mean and divide by standard deviation)\n",
    "    '''\n",
    "    eps = 0.001\n",
    "    if np.std(img) != 0:\n",
    "        img = (img - np.mean(img)) / np.std(img)\n",
    "    else:\n",
    "        img = (img - np.mean(img)) / eps\n",
    "    return img\n",
    "\n",
    "\n",
    "def contains_any_index(root, a_list):\n",
    "    for i, c in enumerate(a_list):\n",
    "        if c.startswith(root):\n",
    "            return i + 1\n",
    "    return 0\n",
    "\n",
    "\n",
    "def get_paths(dir_path, max=1000):\n",
    "    file_paths = []\n",
    "\n",
    "    for i, dir in enumerate(os.listdir(dir_path)):\n",
    "        if max and i >= max:\n",
    "            break\n",
    "        audio = \"\"\n",
    "        beatmaps = []\n",
    "        for file in os.listdir(os.path.join(dir_path, dir)):\n",
    "            if file.endswith(\".mp3\") or file.endswith(\".wav\"):\n",
    "                audio = os.path.join(dir_path, dir, file)\n",
    "            elif file.endswith(\".osu\"):\n",
    "                beatmaps.append(os.path.join(dir_path, dir, file))\n",
    "        file_paths.append((beatmaps, audio))\n",
    "\n",
    "    return file_paths\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    base_path = \"C:/Users/Lysandre/Documents/GitHub/OsuMapCreator/MapCreator/datasets\"\n",
    "    paths = get_paths(os.path.join(base_path, \"maps\"))\n",
    "    data = load_beatmap_attributes(paths[0][0][0])\n",
    "    print(data)\n"
   ],
   "metadata": {
    "id": "Ia32dl6Zmns9"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from keras import layers\n",
    "from tensorflow import keras\n",
    "from MapCreator.Utils.trainingMapParser import *\n",
    "\n",
    "base_path = \"/MapCreator/datasets\"\n",
    "paths = get_paths(os.path.join(base_path, \"maps\"))\n",
    "df, spectrograms, diff = load_beatmaps_and_spectrograms(paths)\n",
    "x_train = spectrograms\n",
    "x_train = np.array(x_train, dtype=float)\n",
    "y_train = df\n",
    "y_train = np.array(y_train, dtype=float)\n",
    "decoder_input = np.zeros((len(y_train), 4001, 13))\n",
    "\n",
    "# Ajout des tokens de dÃ©but et de fin de sÃ©quence\n",
    "index = 0\n",
    "start_of_sequence = np.array([-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0])\n",
    "end_of_sequence = np.array([-2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]).reshape((1, 1, -1))\n",
    "end_of_sequence = np.repeat(end_of_sequence, len(y_train), axis=0)\n",
    "\n",
    "for sublist in decoder_input:\n",
    "    sublist[0] = start_of_sequence\n",
    "    sublist[1:] = y_train[index]\n",
    "\n",
    "y_train = np.append(y_train, end_of_sequence, axis=1)\n",
    "print(y_train[0][-1])\n",
    "\n",
    "print(\"Taille de l'input d'entraÃ®nement : \" + str(x_train.shape))\n",
    "print(\"Taille de l'output d'entraÃ®nement : \" + str(y_train.shape))\n",
    "\n",
    "input_dim = 128\n",
    "decoder_input_shape = 13\n",
    "latent_dim = 256\n",
    "\n",
    "# Model's input\n",
    "input_spectrogram = keras.Input((20000, 128, 1), name=\"input_spectrogram\")\n",
    "# Convolution layer 1\n",
    "x = layers.Conv2D(\n",
    "    filters=64,\n",
    "    kernel_size=[11, 41],\n",
    "    strides=[2, 2],\n",
    "    padding=\"same\",\n",
    "    use_bias=False,\n",
    "    name=\"conv_1\",\n",
    ")(input_spectrogram)\n",
    "x = layers.BatchNormalization(name=\"conv_1_bn\")(x)\n",
    "x = layers.ReLU(name=\"conv_1_relu\")(x)\n",
    "# Convolution layer 2\n",
    "x = layers.Conv2D(\n",
    "    filters=64,\n",
    "    kernel_size=[11, 21],\n",
    "    strides=[1, 2],\n",
    "    padding=\"same\",\n",
    "    use_bias=False,\n",
    "    name=\"conv_2\",\n",
    ")(x)\n",
    "x = layers.BatchNormalization(name=\"conv_2_bn\")(x)\n",
    "x = layers.ReLU(name=\"conv_2_relu\")(x)\n",
    "\n",
    "encoder = keras.layers.LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(x)\n",
    "\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = keras.Input(shape=(None, decoder_input_shape), name=\"input_teacher_forcing\")\n",
    "\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = keras.layers.LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "decoder_dense = layers.Dense(13, activation='relu')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = keras.Model([input_spectrogram, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=keras.losses.MeanAbsoluteError(),\n",
    ")\n",
    "# model.summary()\n",
    "\n",
    "\n",
    "# model.fit(\n",
    "#     [x_train, decoder_input],\n",
    "#     y_train,\n",
    "#     batch_size=1,\n",
    "#     epochs=50,\n",
    "#     # validation_split=0.2\n",
    "# )\n",
    "\n",
    "# Save model\n",
    "model.save(\"MapCreator\")\n",
    "print(\"Sauvegarde du modÃ¨le terminÃ©e\")\n"
   ],
   "metadata": {
    "id": "Lkbclvvcmqpj",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "98920281-2af4-4543-8df2-d6b551946738"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/content/drive/MyDrive/1151466 MIMI - Nanimo nai Youna/audio.mp3\n",
      "[-2. -2. -2. -2. -2. -2. -2. -2. -2. -2. -2. -2. -2.]\n",
      "Taille de l'input d'entraÃ®nement : (5, 20000, 128)\n",
      "Taille de l'output d'entraÃ®nement : (5, 4001, 13)\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_spectrogram (InputLayer)  [(None, 20000, 128)  0          []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " expand_dim (Reshape)           (None, 20000, 128,   0           ['input_spectrogram[0][0]']      \n",
      "                                1)                                                                \n",
      "                                                                                                  \n",
      " conv_1 (Conv2D)                (None, 10000, 64, 3  14432       ['expand_dim[0][0]']             \n",
      "                                2)                                                                \n",
      "                                                                                                  \n",
      " conv_1_bn (BatchNormalization)  (None, 10000, 64, 3  128        ['conv_1[0][0]']                 \n",
      "                                2)                                                                \n",
      "                                                                                                  \n",
      " conv_1_relu (ReLU)             (None, 10000, 64, 3  0           ['conv_1_bn[0][0]']              \n",
      "                                2)                                                                \n",
      "                                                                                                  \n",
      " conv_2 (Conv2D)                (None, 10000, 32, 3  236544      ['conv_1_relu[0][0]']            \n",
      "                                2)                                                                \n",
      "                                                                                                  \n",
      " conv_2_bn (BatchNormalization)  (None, 10000, 32, 3  128        ['conv_2[0][0]']                 \n",
      "                                2)                                                                \n",
      "                                                                                                  \n",
      " conv_2_relu (ReLU)             (None, 10000, 32, 3  0           ['conv_2_bn[0][0]']              \n",
      "                                2)                                                                \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 10000, 1024)  0           ['conv_2_relu[0][0]']            \n",
      "                                                                                                  \n",
      " input_teacher_forcing (InputLa  [(None, None, 13)]  0           []                               \n",
      " yer)                                                                                             \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    [(None, 256),        1311744     ['reshape[0][0]']                \n",
      "                                 (None, 256),                                                     \n",
      "                                 (None, 256)]                                                     \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  [(None, None, 256),  276480      ['input_teacher_forcing[0][0]',  \n",
      "                                 (None, 256),                     'lstm[0][1]',                   \n",
      "                                 (None, 256)]                     'lstm[0][2]']                   \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, None, 13)     3341        ['lstm_1[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,842,797\n",
      "Trainable params: 1,842,669\n",
      "Non-trainable params: 128\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Sauvegarde du modÃ¨le terminÃ©e\n"
     ]
    }
   ]
  }
 ]
}
