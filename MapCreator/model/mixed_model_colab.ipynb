{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLn_pPwzVuSy",
        "outputId": "b041ca71-e583-4b5a-c37c-a9f0b21585e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting audio2numpy\n",
            "  Downloading audio2numpy-0.1.2-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from audio2numpy) (1.22.4)\n",
            "Collecting ffmpeg (from audio2numpy)\n",
            "  Downloading ffmpeg-1.4.tar.gz (5.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: ffmpeg\n",
            "  Building wheel for ffmpeg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpeg: filename=ffmpeg-1.4-py3-none-any.whl size=6083 sha256=99d0a7e897fca8ede7f6dd9b1925b4fb7bc84edbb98e1afaaa6612ae666c245a\n",
            "  Stored in directory: /root/.cache/pip/wheels/8e/7a/69/cd6aeb83b126a7f04cbe7c9d929028dc52a6e7d525ff56003a\n",
            "Successfully built ffmpeg\n",
            "Installing collected packages: ffmpeg, audio2numpy\n",
            "Successfully installed audio2numpy-0.1.2 ffmpeg-1.4\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n"
          ]
        }
      ],
      "source": [
        "!pip install audio2numpy\n",
        "!pip install pydub\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekfF4i8pV2g2",
        "outputId": "ceefb78a-f852-4f33-b507-6e41c1285a94"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import zipfile\n",
        "from enum import Enum\n",
        "\n",
        "import librosa as librosa\n",
        "from dataclasses import dataclass\n",
        "from enum import Enum\n",
        "from typing import List, Optional"
      ],
      "metadata": {
        "id": "Sjr1WXVJepvJ"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_duration(path):\n",
        "    y, sr = librosa.load(path)\n",
        "    return librosa.get_duration(y=y)"
      ],
      "metadata": {
        "id": "rBO88OSbeelf"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def delete_tree(path):\n",
        "    if os.path.exists(path):\n",
        "        if os.path.isdir(path):\n",
        "            shutil.rmtree(path)\n",
        "        else:\n",
        "            os.remove(path)\n",
        "    else:\n",
        "        print(\"path doesn't exists\")"
      ],
      "metadata": {
        "id": "FpWl8ujVehSJ"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def delete_audio_by_duration(files):\n",
        "    for path in files:\n",
        "        duration = get_duration(path)\n",
        "        if duration < 15:\n",
        "          print(f\"duration : {duration} || path : {path}\")\n",
        "          delete_tree(path)"
      ],
      "metadata": {
        "id": "Fw3hBAPfeb0H"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_audio(dir_path):\n",
        "    files = librosa.util.find_files(directory=dir_path, ext=['mp3', 'ogg'], recurse=True)\n",
        "    delete_audio_by_duration(files)"
      ],
      "metadata": {
        "id": "FZQPn-WteWn2"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_clean = \"/content/drive/MyDrive\"\n",
        "filter_audio(path_to_clean)"
      ],
      "metadata": {
        "id": "meBY4Guoe628"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class SectionName(Enum):\n",
        "    General = \"[General]\"\n",
        "    Editor = \"[Editor]\"\n",
        "    Metadata = \"[Metadata]\"\n",
        "    Difficulty = \"[Difficulty]\"\n",
        "    Events = \"[Events]\"\n",
        "    TimingPoints = \"[TimingPoints]\"\n",
        "    Colours = \"[Colours]\"\n",
        "    HitObjects = \"[HitObjects]\"\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class Section:\n",
        "\n",
        "    def value(self, value):\n",
        "        if value.strip().isnumeric():\n",
        "            return int(value)\n",
        "        else:\n",
        "            try:\n",
        "                return float(value)\n",
        "            except ValueError:\n",
        "                return value\n",
        "\n",
        "    def parse_line(self, line: str):\n",
        "        ...\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class HitSample:\n",
        "    normalSet: int = 0  # SampleSet\n",
        "    additionSet: int = 0  # SampleSet\n",
        "    index: int = 0\n",
        "    volume: int = 0\n",
        "    filename: Optional[str] = None\n",
        "\n",
        "    # def set(self, normalSet: int, additionSet: int, index: int, volume: int, filename: Optional[str] = \"\"):\n",
        "    #     self.normalSet = normalSet\n",
        "    #     self.additionSet = additionSet\n",
        "    #     self.index = index\n",
        "    #     self.volume = volume\n",
        "    #     self.filename = filename\n",
        "\n",
        "    def __str__(self):\n",
        "        if self.filename is not None:\n",
        "            return str(f\"{self.normalSet}:{self.additionSet}:{self.index}:{self.volume}:{self.filename}:\")\n",
        "        else:\n",
        "            return str(f\"{self.normalSet}:{self.additionSet}:{self.index}:{self.volume}:\")\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class General(Section):\n",
        "    AudioFilename: Optional[str] = None\n",
        "    AudioLeadIn: int = 0\n",
        "    AudioHash: Optional[str] = None  # deprecated\n",
        "    PreviewTime: int = -1\n",
        "    Countdown: int = 1\n",
        "    SampleSet: str = \"Normal\"\n",
        "    StackLeniency: float = 0.7\n",
        "    Mode: int = 0\n",
        "    LetterboxInBreaks: int = 0\n",
        "    StoryFireInFront: int = 1  # deprecated\n",
        "    UseSkinSprites: int = 0\n",
        "    AlwaysShowPlayfield: int = 0  # deprecated\n",
        "    OverlayPosition: str = \"NoChange\"\n",
        "    SkinPreference: Optional[str] = None\n",
        "    EpilepsyWarning: int = 0\n",
        "    CountdownOffset: int = 0\n",
        "    SpecialStyle: int = 0\n",
        "    WidescreenStoryboard: int = 0\n",
        "    SamplesMatchPlaybackRate: int = 0\n",
        "\n",
        "    def parse_line(self, line: str):\n",
        "        members = line.split(':')\n",
        "        self.__setattr__(members[0], self.value(members[1]))\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class Editor(Section):\n",
        "    Bookmarks: Optional[List[int]] = None\n",
        "    DistanceSpacing: float = 1.22  # between 0.1 and 2.0\n",
        "    BeatDivisor: int = 4\n",
        "    GridSize: int = 4\n",
        "    TimelineZoom: float = 1.0  # between 0.1 and 8.0\n",
        "\n",
        "    def parse_line(self, line: str):\n",
        "        members = line.split(':')\n",
        "        if members[0] == \"Bookmarks\":\n",
        "            self.Bookmarks = [self.value(x) for x in members[1].split(\",\")]\n",
        "        else:\n",
        "            self.__setattr__(members[0], self.value(members[1]))\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class Metadata(Section):\n",
        "    Title: Optional[str] = None\n",
        "    TitleUnicode: Optional[str] = None\n",
        "    Artist: Optional[str] = None\n",
        "    ArtistUnicode: Optional[str] = None\n",
        "    Creator: Optional[str] = None\n",
        "    Version: Optional[str] = None\n",
        "    Source: Optional[str] = None\n",
        "    Tags: Optional[List[str]] = None\n",
        "    BeatmapID: int = 0\n",
        "    BeatmapSetID: int = 0\n",
        "\n",
        "    def parse_line(self, line: str):\n",
        "        members = line.split(':')\n",
        "        if members[0] == \"Tags\":\n",
        "            self.Tags = [x for x in members[1].split(\" \")]\n",
        "        else:\n",
        "            self.__setattr__(members[0], self.value(members[1]))\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class Difficulty(Section):\n",
        "    HPDrainRate: float = 5.0\n",
        "    CircleSize: float = 5.0\n",
        "    OverallDifficulty: float = 5.0\n",
        "    ApproachRate: float = 5.0\n",
        "    SliderMultiplier: float = 1.4\n",
        "    SliderTickRate: float = 1.0\n",
        "\n",
        "    def parse_line(self, line: str):\n",
        "        members = line.split(':')\n",
        "        self.__setattr__(members[0], self.value(members[1]))\n",
        "\n",
        "\n",
        "class EventParams:\n",
        "    pass\n",
        "\n",
        "\n",
        "class Event(Section):\n",
        "    eventType: str\n",
        "    startTime: int\n",
        "    eventParams: List[EventParams]\n",
        "\n",
        "\n",
        "class Background(EventParams):\n",
        "    filename: str\n",
        "    xOffset: int\n",
        "    yOffset: int\n",
        "\n",
        "\n",
        "class Video(EventParams):\n",
        "    Video: 1\n",
        "    startTime: int\n",
        "    filename: str\n",
        "    xOffset: int\n",
        "    yOffset: int\n",
        "\n",
        "\n",
        "class Pause(EventParams):\n",
        "    # 2:Break TODO check wiki because sintaxe is strange\n",
        "    Break: 2\n",
        "    startTime: int\n",
        "    endTime: int\n",
        "\n",
        "\n",
        "#  TODO\n",
        "class Storyboard(EventParams):\n",
        "    pass\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class TimingPoint(Section):\n",
        "    time: int = 0\n",
        "    beatLength: float = 0\n",
        "    meter: int = 0\n",
        "    sampleSet: int = 1  # SampleSet = SampleSet.Normal.value\n",
        "    sampleIndex: int = 0\n",
        "    volume: int = 1\n",
        "    uninherited: int = 0\n",
        "    effects: int = 0  # Effect = None\n",
        "    # bpm: Optional[int] = None\n",
        "\n",
        "    def parse_line(self, line: str):\n",
        "        members = line.split(\",\")\n",
        "        self.time = self.value(members[0])\n",
        "        self.beatLength = self.value(members[1])\n",
        "        self.meter = self.value(members[2])\n",
        "        self.sampleSet = self.value(members[3])\n",
        "        self.sampleIndex = self.value(members[4])\n",
        "        self.volume = self.value(members[5])\n",
        "        self.uninherited = self.value(members[6])\n",
        "        self.effects = self.value(members[7])\n",
        "        # self.calculate_bpm()\n",
        "\n",
        "    # def calculate_bpm(self):\n",
        "    #     self.bpm = round(60000 / self.beatLength)\n",
        "\n",
        "    def calculate_beat_length(self, bpm: int):\n",
        "        self.beatLength = 60000 / bpm\n",
        "\n",
        "    def __str__(self):\n",
        "        return \",\".join([str(value) for value in self.__dict__.values() if value != None])\n",
        "\n",
        "\n",
        "class Colour:\n",
        "    R: int\n",
        "    G: int\n",
        "    B: int\n",
        "\n",
        "\n",
        "# TODO check wiki for colours\n",
        "@dataclass\n",
        "class ColourSection(Section):\n",
        "    colours: List[Colour]\n",
        "    slider_body: Colour\n",
        "    slider_track_override: Colour\n",
        "    slider_border: Colour\n",
        "\n",
        "    # SliderTrackOverride\n",
        "    # SliderBorder\n",
        "    def parse_line(self, line):\n",
        "        members = line.split(\":\")\n",
        "        isCombo = line.startswith(\"Combo\")\n",
        "        split = members[1].split(\",\")\n",
        "        if len(split) != 3 or len(split) != 4:\n",
        "            print(\" invalid color\")\n",
        "            return -1\n",
        "        assert 0 <= split[0] <= 255\n",
        "        assert 0 <= split[1] <= 255\n",
        "        assert 0 <= split[2] <= 255\n",
        "\n",
        "        if isCombo:\n",
        "            # {\"R\": split[0], \"G\": split[1], \"B\": split[2]}\n",
        "            self.colours.append(Colour(R=split[0], G=split[1], B=split[2]))\n",
        "        else:\n",
        "            # do nothing for the moment\n",
        "            pass\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class HitObject(Section):\n",
        "    x: int = 0\n",
        "    y: int = 0\n",
        "    time: int = 0\n",
        "    type: int = 0\n",
        "    hitSound: int = 0\n",
        "    hitSample: Optional[str] = HitSample().__str__()\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"{self.x},{self.y},{self.time},{self.type},{self.hitSound},{self.hitSample}\"\n",
        "\n",
        "    def get_hit_sample(self, line) -> str:\n",
        "        if self.has_hit_sample(line):\n",
        "            return line\n",
        "        return \"0:0:0:0:0:\"\n",
        "\n",
        "    def has_hit_sample(self, line) -> bool:\n",
        "        if type(line) == int or type(line) == float:\n",
        "            return False\n",
        "        else:\n",
        "            return True\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class Cercle(HitObject):\n",
        "\n",
        "    def parse_line(self, line):\n",
        "        members = line.split(\",\")\n",
        "        self.x = self.value(members[0])\n",
        "        self.y = self.value(members[1])\n",
        "        self.time = self.value(members[2])\n",
        "        self.type = self.value(members[3])\n",
        "        self.hitSound = self.value(members[4])\n",
        "        self.hitSample = self.get_hit_sample(self.value(members[-1]))\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class Spinner(HitObject):\n",
        "    endTime: int = 0\n",
        "\n",
        "    def parse_line(self, line):\n",
        "        members = line.split(\",\")\n",
        "        self.x = self.value(members[0])\n",
        "        self.y = self.value(members[1])\n",
        "        self.time = self.value(members[2])\n",
        "        self.type = self.value(members[3])\n",
        "        self.hitSound = self.value(members[4])\n",
        "        self.endTime = self.value(members[5])\n",
        "\n",
        "        self.hitSample = self.get_hit_sample(self.value(members[-1]))\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class CurvePoint:\n",
        "    x: int = 0\n",
        "    y: int = 0\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"{self.x}:{self.y}\"\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class Slider(HitObject):\n",
        "    curvePoints: List[CurvePoint] = None\n",
        "    slides: int = 0\n",
        "    length: float = 0.0\n",
        "    edgeSounds: str = \"\"\n",
        "    edgeSets: str = \"\"\n",
        "    curveType: str = \"\"\n",
        "\n",
        "    def parse_line(self, line):\n",
        "        members = line.split(\",\")\n",
        "        self.x = self.value(members[0])\n",
        "        self.y = self.value(members[1])\n",
        "        self.time = self.value(members[2])\n",
        "        self.type = self.value(members[3])\n",
        "        self.hitSound = self.value(members[4])\n",
        "\n",
        "        # Parse slider points\n",
        "        points = (members[5] or '').split('|')\n",
        "        self.curveType = points[0]\n",
        "        self.curvePoints = []\n",
        "        if len(points):\n",
        "            for i in range(1, len(points)):\n",
        "                coordinates = points[i].split(':')\n",
        "                curve_point = CurvePoint()\n",
        "                curve_point.x = self.value(coordinates[0])\n",
        "                curve_point.y = self.value(coordinates[1])\n",
        "                self.curvePoints.append(curve_point)\n",
        "                # self.curvePoints.append(curve_point.__str__())\n",
        "\n",
        "        # Parse repeat slides bumber & length\n",
        "        self.slides = int(members[6])\n",
        "        self.length = int(round(float(members[7])))\n",
        "\n",
        "        # Parse edgeSounds\n",
        "        if len(members) > 9:\n",
        "            if members[8]:\n",
        "                self.edgeSounds = members[8]\n",
        "\n",
        "            # Parse edgeSets\n",
        "            if members[9]:\n",
        "                self.edgeSets = members[9]\n",
        "\n",
        "        self.hitSample = self.get_hit_sample(self.value(members[-1]))\n"
      ],
      "metadata": {
        "id": "3f6f2NvjYd1u"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import codecs\n",
        "import os\n",
        "import re\n",
        "from typing import List"
      ],
      "metadata": {
        "id": "To2qONwfYaLr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Parse:\n",
        "    def __init__(self):\n",
        "        self.file_format = \"\"\n",
        "        self.general = General()\n",
        "        self.editor = Editor()\n",
        "        self.metadata = Metadata()\n",
        "        self.difficulty = Difficulty()\n",
        "        self.events: List[Event] = []\n",
        "        self.timing_points: List[TimingPoint] = []\n",
        "        self.colours: List[ColourSection] = []\n",
        "        self.hit_objects: List[HitObject] = []\n",
        "\n",
        "        self.osu_section = \"\"\n",
        "\n",
        "    def parse_hit_object_type(self, line):\n",
        "        _type = int(line.split(\",\")[3].strip())\n",
        "        # https://osu.ppy.sh/wiki/fr/Client/File_formats/Osu_%28file_format%29#type\n",
        "        # convert in bit\n",
        "        # 0: Cercle\n",
        "        # 1: Slider\n",
        "        # 3:Spinner\n",
        "        # 7 osu mania\n",
        "        if _type & 1:\n",
        "            cercle = Cercle()\n",
        "            cercle.parse_line(line)\n",
        "            return cercle\n",
        "        elif _type & 2:\n",
        "            slider = Slider()\n",
        "            slider.parse_line(line)\n",
        "            return slider\n",
        "        elif _type & 8:\n",
        "            spinner = Spinner()\n",
        "            spinner.parse_line(line)\n",
        "            return spinner\n",
        "        # elif _type & 128:\n",
        "        #     print(\"mania\")\n",
        "        else:\n",
        "            cercle = Cercle()\n",
        "            cercle.parse_line(line)\n",
        "            print(\"unknown type:\", _type)\n",
        "            return cercle\n",
        "\n",
        "    def parse_line(self, line: str):\n",
        "        line = line.strip()\n",
        "        if not line:\n",
        "            return\n",
        "\n",
        "        match = re.search(r\"\\[(.*?)\\]\", line)\n",
        "        if match:\n",
        "            self.osu_section = match.group(0)\n",
        "            return\n",
        "        match = re.match('^osu file format (v[0-9]+)$', line)\n",
        "        if match:\n",
        "            # self.file_format = line\n",
        "            self.file_format = match.group(1)\n",
        "            return\n",
        "        if self.osu_section == SectionName.General.value:\n",
        "            self.general.parse_line(line)\n",
        "        elif self.osu_section == SectionName.Editor.value:\n",
        "            self.editor.parse_line(line)\n",
        "        elif self.osu_section == SectionName.Metadata.value:\n",
        "            self.metadata.parse_line(line)\n",
        "        elif self.osu_section == SectionName.Difficulty.value:\n",
        "            self.difficulty.parse_line(line)\n",
        "        # elif self.osu_section == SectionName.Events.name:\n",
        "        #     self.events_section.append(line)\n",
        "        elif self.osu_section == SectionName.TimingPoints.value:\n",
        "            timing_point = TimingPoint()\n",
        "            timing_point.parse_line(line)\n",
        "            self.timing_points.append(timing_point)\n",
        "        # elif self.osu_section == SectionName.Colours.name:\n",
        "        #     self.colours_section.append(line)\n",
        "        elif self.osu_section == SectionName.HitObjects.value:\n",
        "            hit_obj = self.parse_hit_object_type(line)\n",
        "            self.hit_objects.append(hit_obj)\n",
        "\n",
        "    def parse_file(self, file):\n",
        "      if os.path.isfile(file):\n",
        "          with codecs.open(file, 'r', encoding=\"utf-8\") as file:\n",
        "              line = file.readline()\n",
        "              while line:\n",
        "                  self.parse_line(line)\n",
        "                  line = file.readline()"
      ],
      "metadata": {
        "id": "YxhBVr3xX5NI"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os.path\n",
        "from typing import List\n",
        "\n",
        "import cv2\n",
        "import librosa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import skimage\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_DfUsUVUXvXP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scale_minmax(X, min=0.0, max=1.0):\n",
        "    X_std = (X - X.min()) / (X.max() - X.min())\n",
        "    X_scaled = X_std * (max - min) + min\n",
        "    return X_scaled\n",
        "\n",
        "\n",
        "def create_images(paths, base_path, max):\n",
        "    for i, p in enumerate(paths):\n",
        "      if i >=max:\n",
        "        break\n",
        "      temp = f\"{base_path}/images/{os.path.basename(os.path.dirname(p[1]))}.png\"\n",
        "      if os.path.exists(temp):\n",
        "          pass\n",
        "      else:\n",
        "          create_image(p[1], base_path)\n",
        "\n",
        "\n",
        "def create_image(audio_path, base_path):\n",
        "    # settings\n",
        "    hop_length = 512  # number of samples per time-step in spectrogram\n",
        "    n_mels = 128  # number of bins in spectrogram. Height of image\n",
        "    time_steps = 384  # number of time-steps. Width of image\n",
        "\n",
        "    # load audio. Using example from librosa\n",
        "\n",
        "    y, sr = librosa.load(audio_path, sr=44100)\n",
        "    out_pure_data = f\"{base_path}/images/{os.path.basename(os.path.dirname(audio_path))}.png\"\n",
        "\n",
        "    # extract a fixed length window\n",
        "    start_sample = 0  # starting at beginning\n",
        "    length_samples = time_steps * hop_length\n",
        "    # window = y[start_sample:start_sample + length_samples]\n",
        "    window = y\n",
        "    # convert to PNG\n",
        "    spectrogram_image(window, sr=sr, out=out_pure_data, hop_length=hop_length, n_mels=n_mels)\n",
        "    print('wrote file', out_pure_data)\n",
        "\n",
        "\n",
        "def spectrogram_image(y, sr, out, hop_length, n_mels):\n",
        "    # use log-melspectrogram\n",
        "    mels = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels,\n",
        "                                          n_fft=hop_length * 2, hop_length=hop_length)\n",
        "    mels = np.log(mels + 1e-9)  # add small number to avoid log(0)\n",
        "\n",
        "    # min-max scale to fit inside 8-bit range\n",
        "    img = scale_minmax(mels, 0, 255).astype(np.uint8)\n",
        "    img = np.flip(img, axis=0)  # put low frequencies at the bottom in image\n",
        "    img = 255 - img  # invert. make black==more energy\n",
        "\n",
        "    # save as PNG\n",
        "    skimage.io.imsave(out, img)\n",
        "\n",
        "\n",
        "def contains_any_index(root, a_list):\n",
        "    for i, c in enumerate(a_list):\n",
        "        if c.startswith(root):\n",
        "            return i + 1\n",
        "    return 0\n",
        "\n",
        "\n",
        "def get_paths(dir_path):\n",
        "    file_paths = []\n",
        "    audio_paths = []\n",
        "    for root, directories, files in os.walk(dir_path):\n",
        "        for filename in files:\n",
        "            if filename.endswith(\".mp3\"):\n",
        "                audio_paths.append(os.path.join(root, filename))\n",
        "    for root, directories, files in os.walk(dir_path):\n",
        "        for filename in files:\n",
        "            if not filename.endswith(\".mp3\"):\n",
        "                filepath = os.path.join(root, filename)\n",
        "                audio_path_index = contains_any_index(root, audio_paths)\n",
        "                if not audio_path_index == 0:\n",
        "                    file_paths.append((filepath, audio_paths[audio_path_index-1]))\n",
        "    # returning all file paths\n",
        "    return file_paths\n",
        "\n",
        "\n",
        "def load_spectrogramm_image(paths,max):\n",
        "  # image = np.zeros((64, 64, 3), dtype=\"uint8\")\n",
        "  images = []\n",
        "  for i, path in enumerate(paths):\n",
        "    if i>= max:\n",
        "      break\n",
        "    image = cv2.imread(path)\n",
        "    images.append(image)\n",
        "  return np.array(images)"
      ],
      "metadata": {
        "id": "mo94QacRYAra"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_beatmap_attributes(path):\n",
        "    cols = [\"x\", \"y\", \"time\", \"type\", \"endtime\", \"x2\", \"2\", \"x3\", \"y3\", \"x4\", \"y4\", \"slide\", \"length\"]\n",
        "\n",
        "    parser = Parse()\n",
        "    parser.parse_file(path)\n",
        "    max_hit_object = 2000\n",
        "    data = np.zeros((13, max_hit_object), dtype=object)\n",
        "\n",
        "    for (i, o) in enumerate(parser.hit_objects):\n",
        "\n",
        "        if i >= max_hit_object:\n",
        "            break\n",
        "\n",
        "        else:\n",
        "\n",
        "            data[0][i] = o.x\n",
        "            data[1][i] = o.y\n",
        "            data[2][i] = o.time\n",
        "            data[3][i] = o.type\n",
        "\n",
        "            if isinstance(o, Cercle):\n",
        "                pass\n",
        "            elif isinstance(o, Spinner):\n",
        "                data[4][i] = o.endTime\n",
        "            elif isinstance(o, Slider):\n",
        "                data[5][i] = o.curvePoints[0].x\n",
        "                data[6][i] = o.curvePoints[0].y\n",
        "\n",
        "                if len(o.curvePoints) > 1:\n",
        "                    data[7][i] = o.curvePoints[1].x\n",
        "                    data[8][i] = o.curvePoints[1].y\n",
        "\n",
        "                if len(o.curvePoints) > 2:\n",
        "                    data[9][i] = o.curvePoints[2].x\n",
        "                    data[10][i] = o.curvePoints[2].y\n",
        "\n",
        "                data[11][i] = o.slides\n",
        "                data[12][i] = o.length\n",
        "\n",
        "    df_t = pd.DataFrame(data).T\n",
        "    df = pd.DataFrame(df_t.values.tolist(), columns=cols)\n",
        "    df = pd.DataFrame(df.values.tolist()).T\n",
        "    # df.drop(df.tail(1).index,\n",
        "    #         inplace=True)\n",
        "    # print(df.loc[len(parser.hit_objects), :])\n",
        "    return data, parser.difficulty.OverallDifficulty"
      ],
      "metadata": {
        "id": "_ibZ_9ewdXpZ"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def load_beatmaps(paths,max):\n",
        "    arr = []\n",
        "    diff = []\n",
        "    for i,path in enumerate(paths):\n",
        "      if i>=max:\n",
        "        break\n",
        "      df_temp, difficulty = load_beatmap_attributes(path[0])\n",
        "      # print(df_temp.shape)\n",
        "      arr.append(df_temp)\n",
        "      diff.append(difficulty)\n",
        "    # print(np.array(arr, dtype=object).shape)\n",
        "    diff = np.array(diff, dtype=float)\n",
        "    df = np.asarray(arr, dtype=object)\n",
        "    return df, diff"
      ],
      "metadata": {
        "id": "ondzfRPedT26"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import the necessary packages\n",
        "from keras.engine.input_layer import InputLayer\n",
        "from keras.models import Sequential\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Activation\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "from keras.layers import concatenate"
      ],
      "metadata": {
        "id": "er_Hew8YZWVr"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_mlp(dim, regress=False):\n",
        "    # define our MLP network\n",
        "    model = Sequential()\n",
        "    model.add(Dense(32, input_dim=dim, activation=\"relu\"))\n",
        "    model.add(Dense(32, activation=\"relu\"))\n",
        "    # check to see if the regression node should be added\n",
        "    if regress:\n",
        "        model.add(Dense(32, activation=\"linear\"))\n",
        "    # return our model\n",
        "    return model"
      ],
      "metadata": {
        "id": "MfTq1EvWc8FG"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_difficulty(shape):\n",
        "  extra = Sequential()\n",
        "  extra.add(Activation('sigmoid', input_shape=(shape,)))\n",
        "  print(extra.output_shape)\n",
        "  return extra"
      ],
      "metadata": {
        "id": "LnJ7_maGc_em"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_cnn(width, height, depth, filters=(16, 32, 64, 128, 256), regress=False):\n",
        "    # initialize the input shape and channel dimension, assuming\n",
        "    # TensorFlow/channels-last ordering\n",
        "    inputShape = (height, width, depth)\n",
        "    chanDim = -1\n",
        "    # define the model input\n",
        "    inputs = Input(shape=inputShape)\n",
        "    # loop over the number of filters\n",
        "    for (i, f) in enumerate(filters):\n",
        "        # if this is the first CONV layer then set the input\n",
        "        # appropriately\n",
        "        if i == 0:\n",
        "            x = inputs\n",
        "        # CONV => RELU => BN => POOL\n",
        "        x = Conv2D(f, (3, 3), padding=\"same\")(x)\n",
        "        x = Activation(\"relu\")(x)\n",
        "        x = BatchNormalization(axis=chanDim)(x)\n",
        "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "        # flatten the volume, then FC => RELU => BN => DROPOUT\n",
        "        x = Flatten()(x)\n",
        "        x = Dense(64)(x)\n",
        "        x = Activation(\"relu\")(x)\n",
        "        x = BatchNormalization(axis=chanDim)(x)\n",
        "        x = Dropout(0.5)(x)\n",
        "        # apply another FC layer, this one to match the number of nodes\n",
        "        # coming out of the MLP\n",
        "        x = Dense(32)(x)\n",
        "        x = Activation(\"relu\")(x)\n",
        "        # check to see if the regression node should be added\n",
        "        if regress:\n",
        "            x = Dense(16, activation=\"linear\")(x)\n",
        "        # construct the CNN\n",
        "        model = Model(inputs, x)\n",
        "        # return the CNN\n",
        "        return model"
      ],
      "metadata": {
        "id": "q-UsbUAjdCMU"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def get_model(trainAttrX_shape, trainDiffX_shape):\n",
        "    # create the MLP and CNN models\n",
        "    mlp = create_mlp(trainAttrX_shape, regress=False)\n",
        "    cnn = create_cnn(64, 64, 3, regress=False)\n",
        "    diff = create_difficulty(trainDiffX_shape)\n",
        "    # create the input to our final set of layers as the *output* of both\n",
        "    # the MLP and CNN\n",
        "    combinedInput = concatenate([mlp.output, cnn.output, diff.output])\n",
        "\n",
        "    x = Dense(64, activation=\"relu\")(combinedInput)\n",
        "    x = Dense(32, activation=\"linear\")(x)\n",
        "    # our final model will accept music spectrogram image/difficulty data on the MLP\n",
        "    # input and images on the CNN input, outputting an array of the same dim as the input of the MLP\n",
        "    model = Model(inputs=[cnn.input, diff.input], outputs=mlp.input)\n",
        "    return model"
      ],
      "metadata": {
        "id": "MNdZ-3mhdE2o"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import the necessary packages\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from keras.layers import Dense\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import concatenate\n",
        "import numpy as np\n",
        "# import argparse\n",
        "import locale\n",
        "import os\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8w_hDborZiwO"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# construct the argument parser and parse the arguments\n",
        "# ap = argparse.ArgumentParser()\n",
        "# ap.add_argument(\"-d\", \"--dataset\", type=str, required=True,\n",
        "# \thelp=\"path to input dataset of house images\")\n",
        "# args = vars(ap.parse_args())\n",
        "\n",
        "# construct the path to the input .txt file that contains information\n",
        "# on each house in the dataset and then load the dataset\n",
        "print(\"[INFO] loading beatmap attributes...\")\n",
        "base_path = \"/content/drive/MyDrive\"\n",
        "\n",
        "paths = get_paths(base_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTbALNiObiFI",
        "outputId": "12bf98fd-2bbe-4417-d8ed-6d49133bd240"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] loading beatmap attributes...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_MAP = 5"
      ],
      "metadata": {
        "id": "xycQB8Ji4pQz"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df, difficulty = load_beatmaps(paths,MAX_MAP)"
      ],
      "metadata": {
        "id": "7pqY7UaYblrN"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_images(paths, \"/content/datasets\", MAX_MAP)"
      ],
      "metadata": {
        "id": "tNbLRWYobm_7"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the spectrogram images and then scale the pixel intensities to the\n",
        "# range [0, 1]\n",
        "print(\"[INFO] loading spectrogram images...\")\n",
        "images = load_spectrogramm_image(\"/content/datasets/images\",MAX_MAP)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jyF8OZobffq",
        "outputId": "45f794da-0716-420c-b5b0-26f7f5239b4a"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] loading spectrogram images...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# partition the data into training and testing splits using 75% of\n",
        "# the data for training and the remaining 25% for testing\n",
        "print(\"[INFO] processing data...\")\n",
        "split = train_test_split(df, images, difficulty, test_size=0.25, random_state=42)\n",
        "(trainAttrX, testAttrX, trainImagesX, testImagesX, trainDifficultyX, testDifficultyX) = split"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2lhdlBV4w0R",
        "outputId": "a09d8875-246c-4b4a-fa0a-8d8bdb3730e0"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] processing data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainAttrX_shape = trainAttrX.shape[1]"
      ],
      "metadata": {
        "id": "fIDHnorl6ZCM"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainDiif_shape= 1"
      ],
      "metadata": {
        "id": "fDOeviA76kub"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create the MLP and CNN models\n",
        "mlp = create_mlp(trainAttrX_shape, regress=False)\n",
        "cnn = create_cnn(64, 64, 3, regress=False)\n",
        "diff = create_difficulty(trainDiif_shape)\n",
        "# create the input to our final set of layers as the *output* of both\n",
        "# the MLP and CNN\n",
        "combinedInput = concatenate([mlp.output, cnn.output, diff.output])\n",
        "\n",
        "x = Dense(64, activation=\"relu\")(combinedInput)\n",
        "x = Dense(32, activation=\"linear\")(x)\n",
        "# our final model will accept music spectrogram image/difficulty data on the MLP\n",
        "# input and images on the CNN input, outputting an array of the same dim as the input of the MLP\n",
        "model = Model(inputs=[cnn.input, diff.input], outputs=mlp.input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGaZfRxp7o_z",
        "outputId": "62240a86-1e63-4d84-c1fd-22ecb9025da9"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_model(trainAttrX_shape,trainDiif_shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwct76Fb5TIo",
        "outputId": "d1129ae6-e3cf-4b91-e64e-fa4f7276dffe"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compile the model using mean absolute percentage error as our loss,\n",
        "# implying that we seek to minimize the absolute percentage difference\n",
        "# between our price *predictions* and the *actual prices*\n",
        "opt = Adam(lr=1e-3, decay=1e-3 / 200)\n",
        "model.compile(loss=\"mean_absolute_percentage_error\", optimizer=opt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_aqC2_m65WpC",
        "outputId": "f13323ae-c633-4ed2-ce1d-deb8c239fb0f"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/optimizers/legacy/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainAttrX = tf.convert_to_tensor(\n",
        "    trainAttrX, dtype=\"float32\"\n",
        ")\n",
        "trainImagesX = tf.convert_to_tensor(\n",
        "    trainImagesX\n",
        ")\n",
        "trainDifficultyX = tf.convert_to_tensor(\n",
        "    trainDifficultyX\n",
        ")"
      ],
      "metadata": {
        "id": "IGe0DAaNHV92"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testAttrX = tf.convert_to_tensor(\n",
        "    testAttrX, dtype=\"float32\"\n",
        ")\n",
        "testImagesX = tf.convert_to_tensor(\n",
        "    testImagesX\n",
        ")\n",
        "testDifficultyX = tf.convert_to_tensor(\n",
        "    testDifficultyX\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "GSZgB49jIsRa",
        "outputId": "de8f3dd3-7f34-436b-830b-e598ecd334c2"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-107-d5687aafc9d9>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtestAttrX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"float32\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m )\n\u001b[0;32m----> 4\u001b[0;31m testImagesX = tf.convert_to_tensor(\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mtestImagesX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    101\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type NoneType)."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train the model\n",
        "print(\"[INFO] training model...\")\n",
        "model.fit(\n",
        "\tx=[trainAttrX, trainImagesX,trainDifficultyX], y=trainAttrX,\n",
        "\tvalidation_data=([testAttrX, testImagesX, testDifficultyX], testAttrX),\n",
        "\tepochs=200, batch_size=8)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "lQyNS4v85Zbo",
        "outputId": "897661f6-8443-4127-82a0-58ab12851e01"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] training model...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-96-2ea983bce22a>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[INFO] training model...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m model.fit(\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrainAttrX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainImagesX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainDifficultyX\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainAttrX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtestAttrX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestImagesX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestDifficultyX\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestAttrX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    101\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type float)."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make predictions on the testing data\n",
        "print(\"[INFO] predicting house prices...\")\n",
        "preds = model.predict([testImagesX,testDifficultyX])"
      ],
      "metadata": {
        "id": "4nAZWDuX5bB3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}